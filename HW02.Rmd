---
title: "Homework 02 - STAT440"
author: "Joseph Sepich (jps6444)"
date: "09/04/2020"
output:
  pdf_document:
    number_sections: false
---

# Problem 1

Which of the following is an appropriate variable name?

* (a) 1st_var
* (b) first_var
* (c) first.var

**first_var or choice b** is the appropriate variables name of the three choices. Variables cannot start with a number and using a dot in the variable name can be confused with function syntax.

# Problem 2

Recall that if $x := (x_1,...,x_d) \in R^d$, then the euclidean norm of $x$ is $||x||_2 = \sqrt{\Sigma_{i=1}^dx_i^2}$. Let

$$
V = [v_1, v_2, v_3, v_4, v_5] = \begin{array}{|c c c c c|}
1 & 2 & 4 & -1 & 0\\
2 & 1 & -4 & 1 & 3\\
3 & 0 & 1 & -1 & 5
\end{array}
$$
Create matrix V in R:

```{r}
mat_v <- matrix(c(1, 2, 3, 2, 1, 0, 4, -4, 1, -1, 1, -1, 0, 3, 5), nrow = 3, ncol=5)
mat_v
```

Use R to do the following

## 2a

Create a matrix $D$ made out of the norm of all pairwise distances of the column vectors of V. That is, the $ij^{th}$ entry of $D$ is $||v_i - v_j||_2$.

```{r}
l2_norm <- function(vec) {
  sqrt(sum(vec^2))
}

num_cols <- dim(mat_v)[2]
mat_d <- matrix(1:25, nrow = num_cols, ncol = num_cols)
for (i in 1:num_cols) {
  for (j in 1:num_cols) {
    mat_d[i, j] <- l2_norm(mat_v[,i] - mat_v[,j])
  }
}
mat_d
```

## 2b

Use $D$ to compute the average and standard deviation of these distances. Be careful not to double count.

```{r}
dists <- mat_d[upper.tri(mat_d,diag=TRUE)]
print(paste0('Average: ', mean(dists)))
print(paste0('Standard Deviation: ', sd(dists)))
```

## 2c

Find vectors $y_j$ so that the $j^{th}$ of $D{y_j}$ is the average distance from $v_j$ to all other points. Report these numbers.

```{r}
mat_d %*% c(0.2,0.2,0.2,0.2,0.2)
```

```{r}
for (i in 1:5) {
  print(mean(mat_d[i,]))
}
```

The vector $y_j = (\frac15,\frac15,\frac15,\frac15,\frac15)$ will make the vector $Dy_j$ the average distance from each column vector to the other vectors, because there are 5 total columns, and matrix vector multiplication will multiply this value by the values in the row (which represent all the distances) and then sum them.

# Problem 3

## 3a

Build a simple linear regression function using ordinary least squares that takes two inputs $x$ and $y$, fits $y$ to $x$, and returns the slope and intercept. Use it to fit the **iron** column to the **calcium** column in the **nutrient** dataset.

```{r}
ols_regress <- function(x, y) {
  slope_numerator <- cov(x, y)
  slope_denom <- var(x)
  slope <- slope_numerator / slope_denom
  inter <- mean(y) - slope * mean(x)
  return(list("slope" = slope, "intercept" = inter))
}
```

```{r}
# load dataset
nutrient_df <- read.csv('./data/nutrient.csv')
```

```{r}
# perform regression
model <- ols_regress(nutrient_df$calc, nutrient_df$iron)
print(paste0('Slope: ', model$slope))
print(paste0('Intercept: ', model$intercept))
```

## 3b

Learn how to use the R function **lm** and use it to fit iron to calcium. Use the **summary** function on the output of **lm** and compare it to the output of your function in (a).

```{r}
model <- lm(iron~calc,data=nutrient_df)
summary(model)
```

The output of the lm function regression of fitting **iron** to **calcium** has the same estimate for the intercept and slope.

# Book Problems

## Chapter 2 Problem 1

Instead of copying the table in the book, use the full dataset Deer.txt, available in Canvas. Use $ instead of c to extract the appropriate columns and give the average for all animals, not just the seven that are shown. Hint: If you need to tell a function not to include NA values. use na.rm=TRUE as an argument.

```{r}
# read dataset
deers <- read.delim('./data/Deer.txt')
```

```{r}
# create length var
Length <- deers$LCT
Tb <- deers$Tb

print(paste0('Average length: ', mean(Length, na.rm = TRUE)))
```

## Chapter 2 Problem 2

```{r}
Farm <- deers$Farm
Month <- deers$Month

Boar <- cbind(Month, Length, Tb)

print(paste0('# of animals: ', nrow(Boar), ' same as ' ,dim(Boar)[1]))
print(paste0('# of vars: ', ncol(Boar), ' same as ', dim(Boar)[2]))
```

## Chapter 2 Problem 5

```{r}
# Confirm data type
print(str(deers))

deers$sqrtLength <- sqrt(deers$LCT)
deers$sqrtLength[1:5]
```

```{r}
deer_list <- list(length = deers$LCT, Farm = Farm)
print(str(deer_list))

deer_list$sqrtLength <- sqrt(deer_list$length)
deer_list$sqrtLength[1:5]
```

There was no real difference in performing the operation in the list versus the data.frame. This holds true, because the data.frame data structure is merely a list with certain rules imposed such as each element/column must be the same length.

## Chapter 2 Problem 6

```{r}
data_file <- './data/ISIT.txt'
bio_read <- read.table(data_file, header = TRUE)
# bio_scan <- scan(data_file, what="character")
bio_scan <- scan(data_file, what = list("", "", "", "", "", "", "", "", "", "", "", "", "", ""))

str(bio_read)
str(bio_scan)

is.data.frame(bio_read)
is.data.frame(bio_scan)
is.matrix(bio_read)
is.matrix(bio_scan)
```

The read.table function will read the text file directly into a data frame object while the scan function will create a single long vector containing each value in the text file. You can also scan each column into separate elements of a list by specifying a list in the what parameter of the scan function.

## Chapter 3 Problem 2

```{r}
# extract data from station 1
station_1 <- bio_read[which(bio_read$Station == 1),]
summary(station_1$SampleDepth)

# extract data from station 2
station_2 <- bio_read[which(bio_read$Station == 2),]
summary(station_2$SampleDepth)

# extract data from station 3
station_3 <- bio_read[which(bio_read$Station == 3),]
summary(station_3$SampleDepth)
```

```{r}
# find low sample size stations
station_counts <- table(bio_read$Station)
station_counts
```

Stations 4 and 5 have considerably fewer observations, so we will omit them.

```{r}
# remove stations 4 and 5
bio_sub <- bio_read[which((bio_read$Station != 4) & (bio_read$Station != 5)),]
unique(bio_sub$Station)
```

```{r}
# extract 2002 data
data <- bio_read[which(bio_read$Year == 2002),]
paste0('# of rows: ', nrow(data))
paste0('Unique years in data: ', unique(data$Year))

# extract April data
data <- bio_read[which(bio_read$Month == 4),]
paste0('# of rows: ', nrow(data))
paste0('Unique months in data: ', unique(data$Month))

# extract measurements greater than 2000m depth
data <- bio_read[which(bio_read$SampleDepth > 2000),]
paste0('# of rows: ', nrow(data))
paste0('Min depth of data: ', min(data$SampleDepth))

# show data by increasing depth values
data <- bio_read[order(bio_read$SampleDepth),]
data[1:20,]

# show data at depths > 2000 in April
data <- bio_read[which((bio_read$SampleDepth > 2000) & (bio_read$Month == 4)),]
data[1:20,]
```

# Sampling Basics

## Problem 1

Obtain 1000 samples from the chi-squared distribution with 1 degree of freedom by first sampling 1000 samples $Z_i$ from a standard normal distribution, and then applying the appropriate transformation. Plot a histogram of the results. Overlay a curve onto the histogram denoting the true density.

```{r}
# standard normal sample
num <- 1000
samples <- rnorm(num)
```

Recall the definition of a chi-square distribution with k degrees of freedom:

\[Q = \Sigma_{i=1}^kZ_i^2\]

For one degree of freedom this would merely be squaring each sample.

\[Q_i = Z_i^2\]

```{r}
# transform
chi_samples <- samples^2
# histogram
hist(chi_samples)

# overlay true density
df <- 1
x <- seq(0, 12, 0.1)
y <- dchisq(x, df) * num
lines(x,y)
```

## Problem 2

Repeat the previous question, but produce t-distributed random variables with 5 degrees of freedom. Do this by only generating standard normals (then transforming them the appropriate way).

Recall the Student's t distribution follows the formula below where the distribution has $n$ degrees of freedom.

\[\frac{Z}{\sqrt{\chi^2/n}}\]


```{r}
df <- 5
t <- vector(mode='numeric', length=num)
z_samples <- rnorm(df * num)
samples <- rnorm(num)
test <- c(0)
for (i in seq(1, df * num, df)) {
  start <- i
  end <- i + df -1
  sub_samp <- z_samples[start:end]
  test <- append(test, sub_samp)
  chi <- sum(sub_samp^2)
  t[i/df] <- samples[i/df] / (sqrt(chi / df))
}
hist(t)

# overlay true sample
x <- seq(-20, 20, 0.1)
y <- dt(x, df) * num
lines(x,y)
```
